{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 13250
    },
    "colab_type": "code",
    "id": "POnDImVWgyMK",
    "outputId": "70e15344-212a-47c4-d9a1-e5dc71bdfdcb"
   },
   "outputs": [],
   "source": [
    "!rm -r data\n",
    "!rm -r GTdb_crop.zip\n",
    "!rm -r GTdb_crop\n",
    "!wget http://www.anefian.com/research/GTdb_crop.zip\n",
    "!unzip GTdb_crop.zip -d GTdb_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bpDvPD4R-cnN"
   },
   "outputs": [],
   "source": [
    "import os, glob, random\n",
    "import shutil\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as img_transf\n",
    "from torchvision import datasets as ds\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PHfBn59plOPz"
   },
   "outputs": [],
   "source": [
    "os.mkdir(\"data\")\n",
    "for i in range(1, 51):\n",
    "    pattern = \"s\"+str(i).zfill(2)\n",
    "    path = 'data/'+str(pattern)\n",
    "    f = sorted(glob.glob(os.path.join(\"GTdb_crop/cropped_faces/\", pattern+\"*\")))\n",
    "    os.mkdir(path)\n",
    "    [shutil.copy(i, path) for i in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uFlh9K2Jg_sN"
   },
   "outputs": [],
   "source": [
    "src = \"data/\"\n",
    "d = os.listdir(\"data\")\n",
    "for i in range(3):\n",
    "    r = random.choice(d)\n",
    "    shutil.copytree(src + r, \"data/testing/\"+r)\n",
    "    d.remove(r)\n",
    "else:\n",
    "    for i in sorted(d):\n",
    "        shutil.copytree(src + i, \"data/training/\"+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MRHr0GTihzAo"
   },
   "outputs": [],
   "source": [
    "class SiaDataset(Dataset):\n",
    "    def __init__(self, imageDir, image_transforms=None, gray_scale=False):\n",
    "        self.imageDir = imageDir\n",
    "        self.image_transforms = image_transforms\n",
    "        self.gray_scale = gray_scale\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        im1 = self.imageDir.imgs[idx]\n",
    "        match = random.randint(0,1) \n",
    "        if match:\n",
    "            im2 = self.imageDir.imgs[idx]\n",
    "        else:\n",
    "            im2 = random.choice(self.imageDir.imgs)\n",
    "\n",
    "        img1 = Image.open(im1[0]).convert(\"RGB\")\n",
    "        img2 = Image.open(im2[0]).convert(\"RGB\")\n",
    "        label = torch.from_numpy(np.array([int(im1[1]==im2[1])], dtype=np.float32))\n",
    "        \n",
    "        if self.gray_scale:\n",
    "            img1 = img1.convert(\"L\")\n",
    "            img2 = img2.convert(\"L\")\n",
    "        \n",
    "        if self.image_transforms:\n",
    "            img1 = self.image_transforms(img1)\n",
    "            img2 = self.image_transforms(img2)\n",
    "        return img1, img2, label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imageDir.imgs)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dnTeyqVAs9Gs"
   },
   "outputs": [],
   "source": [
    "class Siamese(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Siamese, self).__init__()\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=10),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "        self.cnn2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=7),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.BatchNorm2d(128)\n",
    "        )\n",
    "        \n",
    "        self.cnn3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.BatchNorm2d(128)\n",
    "        )\n",
    "        \n",
    "        self.cnn4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(256)\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(256*6*6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, 8),\n",
    "        )\n",
    "    \n",
    "    def forward(self, img1, img2):\n",
    "        img1 = self.cnn1(img1)\n",
    "        img1 = self.cnn2(img1)\n",
    "        img1 = self.cnn3(img1)\n",
    "        img1 = self.cnn4(img1)\n",
    "        img1 = img1.view(img1.size()[0], -1)\n",
    "        img1 = self.fc1(img1)\n",
    "        \n",
    "        img2 = self.cnn1(img2)\n",
    "        img2 = self.cnn2(img2)\n",
    "        img2 = self.cnn3(img2)\n",
    "        img2 = self.cnn4(img2)\n",
    "        img2 = y.view(img2.size(0), -1)\n",
    "        img2 = self.fc1(img2)\n",
    "        return img1, img2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UOio7d3x_DaU"
   },
   "outputs": [],
   "source": [
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
    "                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "\n",
    "\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fdYMuXViyTUl"
   },
   "outputs": [],
   "source": [
    "def show(img,text=None):\n",
    "    img = img.numpy()\n",
    "    plt.axis(\"off\")\n",
    "    plt.text(75,120 , text, fontweight='bold')\n",
    "    plt.imshow(np.transpose(img, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m1QJ1Jvvh2Md"
   },
   "outputs": [],
   "source": [
    "im_trans = img_transf.Compose([img_transf.Resize((105,105)),img_transf.ToTensor()])\n",
    "\n",
    "folder_dataset = ds.ImageFolder(\"data/training\")\n",
    "\n",
    "sia_dataset = SiaDataset(imageDir=folder_dataset,\n",
    "                                        image_transforms=im_trans,\n",
    "                                        gray_scale=False)\n",
    "train_dataloader = DataLoader(sia_dataset,\n",
    "                        shuffle=True,\n",
    "                        num_workers=8,\n",
    "                        batch_size=64)\n",
    "\n",
    "folder_dataset = ds.ImageFolder(\"data/testing\")\n",
    "\n",
    "siatest_dataset = SiaDataset(imageDir=folder_dataset,\n",
    "                                        image_transforms=im_trans,\n",
    "                                        gray_scale=False)\n",
    "\n",
    "\n",
    "test_dataloader = DataLoader(siatest_dataset,num_workers=6,batch_size=1,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5q6MWPfbh9iL"
   },
   "outputs": [],
   "source": [
    "net = Siamese().cuda()\n",
    "loss_fun = ContrastiveLoss() \n",
    "optims = optim.Adam(net.parameters(),lr = 0.0003 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3820
    },
    "colab_type": "code",
    "id": "aYpd1jBexQ6B",
    "outputId": "db24fe6f-0798-4b83-d262-8327011c739b"
   },
   "outputs": [],
   "source": [
    "counter = []\n",
    "l = [] \n",
    "iter_num= 0\n",
    "\n",
    "for epoch in range(0,100):\n",
    "    for i, data in enumerate(train_dataloader,0):\n",
    "        img0, img1 , label = data\n",
    "        img0, img1 , label = img0.cuda(), img1.cuda() , label.cuda()\n",
    "        optims.zero_grad()\n",
    "        op1,op2 = net(img0,img1)\n",
    "        loss = loss_fun(op1,op2,label)\n",
    "        loss.backward()\n",
    "        optims.step()\n",
    "        if i %12 == 0 :\n",
    "            print(\"Epoch {} with {} loss\\n\".format(epoch,loss.item()))\n",
    "            iter_num +=5\n",
    "            counter.append(iter_num)\n",
    "            l.append(loss.item())\n",
    "plt.plot(counter,l)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 12122
    },
    "colab_type": "code",
    "id": "P7jN8rIx3EZn",
    "outputId": "b6a7b490-3a05-4762-f734-dfce03fcb5b3"
   },
   "outputs": [],
   "source": [
    "for i, data in enumerate(test_dataloader, 0):\n",
    "    img0, img1 , label = data\n",
    "    concatenated = torch.cat((img0,img1))\n",
    "    output1,output2 = net(Variable(img0).cuda(),Variable(img1).cuda())\n",
    "    distance = F.pairwise_distance(output1, output2)\n",
    "    show(torchvision.utils.make_grid(concatenated),'Missmatch: {:.3f}'.format(distance.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "oneshot.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
